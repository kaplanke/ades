\documentclass{ws-procs9x6}

\begin{document}

\title{FAST LANE TRACKING USING HMM AND MHT FOR\\
AUTONOMOUS URBAN DRIVING}

\author{KEMAL KAPLAN, CANER KURTUL and H.LEVENT AKIN}

\address{Department of Computer Engineering, Bo{\u g}azi{\c c}i University\\
Istanbul, Turkey}

\begin{abstract}
Lane tracking is one of the most important processes for autonomous vehicles because the navigable region usually stands between the lanes, especially in urban environments. Hough transform is one of the most popular algorithms for lane detection. A robust lane tracking method is also required for reducing the effect of the noise and the required processing time. In this paper, we present a new lane tracking method which uses a partitioning technique for obtaining multiresolution Hough Transform (MHT) of the acquired vision data. After the detection process, for tracking the detected lanes, a Hidden Markov Model (HMM) based method is proposed. This work is a part of the ADES (Automatic Driver Evaluation System) Project in Artificial Intelligence Laboratory of Bo{\u g}azi{\c c}i University.
\end{abstract}

\section{Introduction}

\noindent Although the vehicle manufacturers deploy more intelligence in their newest models, the current applications are usually focused on driver assistance and early warning systems. However, in the near future, intelligent vehicles will also enforce the traffic regulations. For example, speed limit and traffic light violations are going to be detected by cars. With this motivation, the aim of the ADES project is to develop a framework for evaluating the drivers against the traffic rules. The applications of the resulting system include but not limited to the following items;

\begin{itemize}
    \item Deter drivers from violating traffic rules
    \item Automation of driver license examinations
    \item Supervising the development of autonomous urban driving
\end{itemize}

\noindent The project can be divided into two major parts. The first part is acquiring the necessary information from various sensors where the second part is processing these knowledge to evaluate the driver's actions. 

\noindent In this work we present a new approach for obtaining lane boundaries from vision data. The proposed approach uses MHT for detecting lane markers followed by an HMM model for tracking them. 

\section{Related Work}

\noindent For lane detection, Hough Transform [1] is one of the most common techniques [2, 3, 4]. However, there are many other techniques in the literature for lane detection. Pomerleau et al. [5] used neural networks in their placeplaceALVIN system. Dynamic programming is used for eliminating outliners from detected line segments by Kang et al. [6].  In addition, Wang et al. [7] used B-splines in order to fit lane markings. Different techniques have also been proposed for tracking the detected lanes and modeling the road. Kalman filtering [8] and particle filtering [9, 10] are the two most common tracking techniques used in lane tracking methods. A more detailed survey for lane detection strategies can be found on [11].

\section{Proposed Approach}

\noindent The proposed approach employs MHT for lane detection, followed by two HMM models for radius and orientation of the candidate lanes.


\subsection{Multiresolution Hough Transform}

\noindent The classical Hough transformation approach processes the entire vision data in order to detect the lines. This scenario has two main drawbacks. First, the occluded lines (i.e. another car passing through the line) become noisy since the transformed relative intensity of the line decreases. Second, the relative intensity of the lines also decreases at the curves in the road. The proposed solution divides the road image into partitions, where the sizes of the partitions are inversely proportional to the distance of the partition to the vehicle. 

\noindent After the image is partitioned, several preprocessing steps are required before applying the Hough transform. These preprocessing steps should be fast because the Hough transform is already computationally expensive for real time applications. Since edge detection techniques are usually computationally expensive for real time applications [12, 13], each partition is converted to binary images via applying a threshold filter after a color remapping process. 

\begin{figure}
\begin{center}
\psfig{file=fig1.eps,scale=0.5}
\end{center}
\caption{(a) Partitioned image, (b) Binary image.}
\label{aba:fig1}
\end{figure} 

\noindent After the image is partitioned, a separate Hough transformation is applied to each single partition. The most intense line in each partition, which is the candidate line segment, is taken into consideration in order to find the global lanes in the image. Since the Hough lines are represented in polar coordinates \textit{(r, $\theta $)} instead of rectangular coordinates \textit{(x, y)}, the candidate lines are grouped according to their slopes and distances to the center of the image as well as their intensities. The center of the frame is chosen as the bottom point. 

\begin{figure}
\begin{center}
\psfig{file=fig2.eps,scale=0.5}
\end{center}
\caption{(a) Candidate lines, (b) Transformed line, (c) Detected lines.}
\label{aba:fig2}
\end{figure} 

\noindent The transformation of the lines basically changes the center point of the polar coordinates for each transformed line which is achieved by the following translation

\begin{equation} \label{GrindEQ__1_} 
\begin{array}{l} {r'\, \, =\, r+(x-x')\cos (\theta )+(y-y')\sin (\theta )} \\ {\theta '=\, \theta } \end{array} 
\end{equation} 


\noindent where \textit{(r', $\theta $')} is the polar coordinates of the transformed Hough line \textit{(r, $\theta $)}. Note that the translation of the center of the Hough transformation is from \textit{(x, y)} to \textit{(x', y')}. 

\noindent After the lines are grouped, the most intense three clusters are assigned as the lanes. However, there may be less than three lanes if the sum of the intensities of the candidate lines is less than a threshold value.


\subsection{Lane Tracking}

\noindent For lane tracking, HMM is used to represent the relation between the current frame and its successor. Each line in a specific frame is represented by an individual \textit{(r, $\theta $)} pair. In the succeeding frame, the process will most probably observe the same line at \textit{(r', $\theta $')} which is not very far from the position of the line in the previous frame. The probability of observing \textit{(r', $\theta $')} pair in the next frame is modeled as an HMM problem. In addition, \textit{$\theta $} and r values are modeled by two different HMM. The \textit{$\theta $} value is discretized as (0, 1, 2, 3\dots 178, 179) where the \textit{r} value is discretized at the pixel level. This discretization schema is used in both transmission and emission matrixes. The emission probability matrix shows the probability of observing \textit{$\theta $'} (or \textit{r'}) in the next frame, having observed \textit{$\theta $} (or \textit{r}) in the current frame. In our implementation, the observation and state transition matrix values are derived from two Gaussian distributions with different deviations. The deviation of the transition matrix is assigned to a smaller value than the observation matrix, which means, the state transition matrix aims to preserve the current state where the observation matrix promotes the exploration behavior.

\section{Experiment}

\noindent The proposed approach is implemented and tested on a relatively short video sequence of an urban drive. In addition, the new approach is compared with the classical Hough transform where the entire image is processed and the most intense lines are accepted as candidate lines. The properties of the video are given in \ref{aba:table1}.

\begin{table}
\tbl{Properties of video sequence.}
{\begin{tabular}{@{}cccc@{}}
\psfig{file=table1.eps,scale=0.5}
\end{tabular}
}
\label{aba:table1}
\end{table}

\subsection{Setup}

\noindent As the first step of the experiment, the image is converted to a binary image by using color remapping. The mapping for each pixel from 24bit RGB value to binary value is given in Table 2.

\begin{table}
\tbl{Color remapping.}
{\begin{tabular}{@{}cccc@{}}
\psfig{file=table2.eps,scale=0.5}
\end{tabular}
}
\label{aba:table2}
\end{table}

\noindent This binarization favors the white and yellow parts of the images. The values are manually crafted for the video sample. More discussions about improving the color remapping can be found in the next section.

\noindent The next step is to determine the partitions of the image on which the Hough transforms will be applied. Although the image is 288 pixels high, only the bottommost 116 pixels are used since the road remains in this lower part of the image. The accuracy of this assumption may slightly differ depending on the slope.

\begin{figure}
\begin{center}
\psfig{file=fig3.eps,scale=0.5}
\end{center}
\caption{Image partitions.}
\label{aba:fig3}
\end{figure} 

\noindent The widths of the partitions are 32, 64, and 128 pixels from top to bottom. And the heights are 32, 42, and 42 pixels respectively as shown in Figure 3. These values are assigned according to the position of the camera. After the partitions are calculated, Hough transformation is applied to each partition as described in the previous section.  The most promising three lines are assigned as the candidate lane markers. But there may be less than three lines if the intensity of the calculated lines are less than an empirically assigned threshold. The experiment shows that the proposed approach usually detects only two lines most of the time.

\noindent After finding the lane markers, HMM method is used to track the lanes. The values of the emission and transition matrices are derived using Gaussian assumption. The deviation of the transition matrix is assigned as 1 and the deviation of the emission matrix is taken as 2. Two separate models are prepared for the \textit{$\theta $} and \textit{r} values of the candidate lane markers. The transition and emission matrices are given in Tables 3 and 4. Since the \textit{$\theta $} values 0 and 179 are actually very close, the emission and transmission values are the same for 1 and 179 in \textit{$\theta $} matrices. In addition, the range of the \textit{r} matrices is (0, 282) because the maximum possible distance for any detected line is 282 pixels where the height of the processed part of the image is 116 and width of the image is 512.

\begin{table}
\tbl{(a) Transmission matrix for \textit{r}, (b) Transmission matrix for \textit{$\theta $}.}
{\begin{tabular}{@{}cccc@{}}
\psfig{file=table3.eps,scale=0.45}
\end{tabular}
}
\label{aba:table3}
\end{table}

\begin{table}
\tbl{(a) Emission matrix for \textit{r}, (b) Emission matrix for \textit{$\theta $}.}
{\begin{tabular}{@{}cccc@{}}
\psfig{file=table4.eps,scale=0.5}
\end{tabular}
}
\label{aba:table4}
\end{table}


\subsection{Results}

\noindent The proposed approach managed to detect and track at least one line in most of the sequence. In addition, false positives are reduced to an acceptable level. In order to validate the results, the proposed approach is compared with the classical Hough Transform approach. In this method, the same part of the image is processed using the Hough transform routine. The most intensive 10 lines are merged according to their \textit{r }and \textit{$\theta $} values. Finally three or less candidate lines are selected as the lane markers. 

\noindent The major differences between the two approaches are shown in Figure 4. The images on the left hand side are the detected or missed lines by the classical approach. The right hand side images are the outputs of the new approach for the same frames which show that the new approach is more robust and accurate.

\noindent The computational cost of the proposed approach can be compared as follows. The average processing time is 21.25 milliseconds for a laptop PC with Intel T2050 processor at 1.6 GHz whereas the average cost of the classical approach is 15.29 milliseconds. 

\noindent The results of the experiments for both the proposed approach and the classical method can be found in the project website [15].


\section{Conclusions}

\noindent Lane tracking is one of the major tasks in autonomous urban driving. A hybrid solution of MHT with HMM is applied in this work, and the performance of the system is increased. However there are certain assumptions and shortcomings of the proposed approach. First of all, variable lightning and road conditions require adaptive color remapping. Although this is beyond the scope of this work, it is crucial for a final product. In addition, the proposed approach models the lane boundaries as lines, therefore an approximation is inevitable at curves. However, it is also possible to use combination of line segments which are detected at each image partition. As another future work, the emission matrix can be updated on the fly by already made decisions.

\begin{figure}
\begin{center}
\psfig{file=fig4.eps,scale=0.5}
\end{center}
\caption{Differences between classical Hough transformation and proposed approach.}
\label{aba:fig4}
\end{figure}

\noindent \textbf{\eject References}

\noindent \begin{enumerate}
\item P.V. Hough (1962) Methods and means for recognizing complex patterns. US Patent 3069654.

\noindent \item Li, Q., Zheng, N. and Cheng, H. (2004) Springrobot: A prototype autonomous vehicle and its algorithms for lane detection. IEEE Transactions on Intelligent Transportation Systems, 5(4):300-308.

\noindent \item Yu, B. and Jain, A.K. (1997) Lane boundary detection using a multiresolution Hough transform.

\noindent \item McCall, J.C. and Trivedi, M.M. (2006) Video-based lane estimation and tracking for driver assistance: survey, system, and evaluation. IEEE Transactions on Intelligent Transportation Systems, 7(1):20-37.

\noindent \item Dean Pomerleau (1995) Neural Network Vision for Robot Driving. In The Handbook of Brain Theory and Neural Networks.

\noindent \item Kang, D.J. and Jung, M.H. (2003) Road lane segmentation using dynamic programming for active safety vehicles. Pattern Recognition Letters, 24(16):3177-3185.

\noindent \item Wang, Y., Teoh, E.K. and Shen, D. (2004) Lane detection and tracking using B-Snake. Image and Vision Computing, 22(4):269-280.

\noindent \item Kreucher, C., Lakshmanan, S. and Kluge, K. (1998) A driver warning system based on the LOIS lane detection algorithm.

\noindent \item Apostoloff, N. and Zelinsky, A. (2003) Robust vision based lane tracking using multiple cues and particle filtering.

\noindent \item Zhou, Y., Xu, R., Hu, X. and Ye, Q. (2006) A robust lane detection and tracking method based on computer vision. Measurement Science and Technology, 17(4):736-745.

\noindent \item McCall, J.C. and Trivedi, M.M. (2006) Video-based lane estimation and tracking for driver assistance: survey, system, and evaluation. IEEE Transactions on Intelligent Transportation Systems, 7(1):20-37.

\noindent \item Canny, J. (1986) A computational approach to edge detection. IEEE Trans. Pattern Anal. Mach. Intell., 8(6):679-698.

\noindent \item Ratnayake, K. and Amer, A. (2006) An FPGA-Based Implementation of Spatio-Temporal Object Segmentation. In Image Processing, 2006 IEEE International Conference on., pages 3265-3268.

\noindent \item Rabiner, L. and Juang, B. (1986) An introduction to hidden Markov models. ieee assp magazine, 3(1 Part 1):4-16.

\noindent \item ADES project website, http://robot.cmpe.boun.edu.tr/ADES.
\end{enumerate}


\end{document}

